{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification\n",
    "This is a notebook whose purpose is to give a better intuition about the Binary Classification environment.\n",
    "\n",
    "Let's start by creating the environment itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures.thread import ThreadPoolExecutor\n",
    "\n",
    "from edesdetectrl.dataloaders.echonet import Echonet\n",
    "import edesdetectrl.environments.binary_classification\n",
    "import gym\n",
    "from edesdetectrl.config import config\n",
    "\n",
    "volumetracings_csv_file = config[\"data\"][\"volumetracings_path\"]\n",
    "filelist_csv_file = config[\"data\"][\"filelist_path\"]\n",
    "videos_dir = config[\"data\"][\"videos_path\"]\n",
    "split = \"TEST\"\n",
    "thread_pool_executor = ThreadPoolExecutor()\n",
    "echonet = Echonet(\"TEST\")\n",
    "seq_iterator = echonet.get_random_generator(42, thread_pool_executor, 5)\n",
    "env = gym.make(\"EDESClassification-v0\", seq_iterator=seq_iterator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation = env.reset()\n",
    "num_channels = observation.shape[0]\n",
    "print(f\"Shape of observation: {observation.shape} <- (num_channels, width, height)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at what an observation looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(ncols=num_channels, figsize=(16, 8), dpi=100)\n",
    "\n",
    "current_frame = int(num_channels/2)\n",
    "for i in range(num_channels):\n",
    "    if i == current_frame:\n",
    "        axes[i].set_title(\"↓ Current frame ↓\")\n",
    "    elif i == current_frame-1:\n",
    "        axes[i].set_title(\"←← Previous frames\")\n",
    "    elif i == current_frame+1:\n",
    "        axes[i].set_title(\"Next frames →→\")\n",
    "        \n",
    "    axes[i].imshow(observation[i], cmap='copper' if i == current_frame else 'gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations are pre-processed as a first step as part of the neural network model. This is what the processed observation looks like.\n",
    "\n",
    "_NB! Pre-processing is currently bugged and is not in use._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import edesdetectrl.model as model\n",
    "import jax.numpy as jnp\n",
    "\n",
    "# Expected input shape is (batch_size, width, height, channels)\n",
    "# Observation shape is (channels, width, height)\n",
    "observation_reshaped = jnp.expand_dims(jnp.transpose(observation, (1,2,0)),0)\n",
    "pre_processed_observation = model.pre_process_frames(observation_reshaped)\n",
    "fig, axes = plt.subplots(ncols=num_channels, figsize=(16, 8), dpi=100)\n",
    "\n",
    "current_frame = int(num_channels/2)\n",
    "for i in range(num_channels):\n",
    "    if i == current_frame:\n",
    "        axes[i].set_title(\"↓ Current frame ↓\")\n",
    "    elif i == current_frame-1:\n",
    "        axes[i].set_title(\"←← Previous frames\")\n",
    "    elif i == current_frame+1:\n",
    "        axes[i].set_title(\"Next frames →→\")\n",
    "        \n",
    "    axes[i].imshow(pre_processed_observation[0,:,:,i], cmap='copper' if i == current_frame else 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "Let's look at how a trained model performs. To run this code, you must have an already trained model available under config data->trained_params_path. See `config_upstream.toml`.\n",
    "\n",
    "The agent in the below script is following the trained Q-function greedily, meaning that it will always select the action that it thinks is better (no exploring). We add the Q-values to a list as well as the rewards received so that we can plot below. Instead of plotting the Q-values directly, we plot the so-called advantage. Put simply, advantage is the Q-values minus the average of the Q-values. In this case, this is just to make the plots easier to read.\n",
    "\n",
    "The blue and orange lines represents the estimated advantage of taking the D or S actions, respectively. When D has a higher value than S, the agents selects D, and vice-versa. The green line represents the reward, and will be 1 if the selected action was correct, otherwise it will be 0. A perfect agent would take actions such that the reward, the green line, is always 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import haiku as hk\n",
    "import jax\n",
    "from edesdetectrl.util import functional\n",
    "\n",
    "network = functional.chainf(\n",
    "    model.get_func_approx(env.action_space.n),\n",
    "    hk.transform,\n",
    "    hk.without_apply_rng,\n",
    ")\n",
    "with open(config[\"data\"][\"trained_params_path\"], \"rb\") as f:\n",
    "    trained_params = pickle.load(f)\n",
    "q = jax.jit(lambda s: network.apply(trained_params, s)[0])\n",
    "\n",
    "\n",
    "s = env.reset()\n",
    "done = False\n",
    "\n",
    "states = [s]\n",
    "actions = []\n",
    "rewards = []\n",
    "q_values = []\n",
    "while not done:\n",
    "    qs = q(s)\n",
    "    a = jnp.argmax(qs)\n",
    "    s, r, done, info = env.step(a)\n",
    "\n",
    "    states.append(s)\n",
    "    actions.append(a)\n",
    "    rewards.append(r)\n",
    "    q_values.append(qs)\n",
    "\n",
    "\n",
    "def calc_advantage(t):\n",
    "    d, s = t\n",
    "    v = (d + s) / 2\n",
    "    return d - v, s - v\n",
    "\n",
    "\n",
    "advantage = list(map(calc_advantage, q_values))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(advantage)\n",
    "ax.plot(rewards)\n",
    "ax.legend([\"Diastole\", \"Systole\", \"Reward\"])\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8c874da82c45311228f313b6f39f3c34909c3af42cf779d57954a522c91027b5"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('ed_es_detect_rl-w7qqMI3V': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
