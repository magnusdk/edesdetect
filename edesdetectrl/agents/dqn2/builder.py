from typing import Callable, Iterator, List, Optional

import numpy as np
import optax
import reverb
from acme import adders, core, specs
from acme.adders import reverb as adders_reverb
from acme.agents.jax import actor_core as actor_core_lib
from acme.agents.jax import actors, builders
from acme.agents.jax.ppo import config as ppo_config
from acme.agents.jax.ppo import learning
from acme.agents.jax.ppo import networks as ppo_networks
from acme.jax import networks as networks_lib
from acme.jax import variable_utils
from acme.jax.types import Networks, PolicyNetwork, Sample
from acme.utils import counting, loggers
from edesdetectrl.agents.dqn2.config import DQNConfig


class DQNBuilder(builders.ActorLearnerBuilder):
    """Defines an interface for defining the components of an RL agent.

    Implementations of this interface contain a complete specification of a
    concrete RL agent. An instance of this class can be used to build an
    RL agent which interacts with the environment either locally or in a
    distributed setup.
    """

    def __init__(
        self,
        config: DQNConfig,
        logger_fn: Callable[[], loggers.Logger] = lambda: None,
    ):
        self._config = config
        self._logger_fn = logger_fn

    def make_replay_tables(
        self,
        environment_spec: specs.EnvironmentSpec,
    ) -> List[reverb.Table]:
        """Create tables to insert data into."""
        pass

    def make_dataset_iterator(
        self,
        replay_client: reverb.Client,
    ) -> Iterator[Sample]:
        """Create a dataset iterator to use for learning/updating the agent."""
        pass

    def make_adder(
        self,
        replay_client: reverb.Client,
    ) -> Optional[adders.Adder]:
        """Create an adder which records data generated by the actor/environment.

        Args:
          replay_client: Reverb Client which points to the replay server.
        """
        pass

    def make_actor(
        self,
        random_key: networks_lib.PRNGKey,
        policy_network: PolicyNetwork,
        adder: Optional[adders.Adder] = None,
        variable_source: Optional[core.VariableSource] = None,
    ) -> core.Actor:
        """Create an actor instance.

        Args:
          random_key: A key for random number generation.
          policy_network: Instance of a policy network; this should be a callable
            which takes as input observations and returns actions.
          adder: How data is recorded (e.g. added to replay).
          variable_source: A source providing the necessary actor parameters.
        """
        pass

    def make_learner(
        self,
        random_key: networks_lib.PRNGKey,
        networks: Networks,
        dataset: Iterator[Sample],
        replay_client: Optional[reverb.Client] = None,
        counter: Optional[counting.Counter] = None,
    ) -> core.Learner:
        """Creates an instance of the learner.

        Args:
          random_key: A key for random number generation.
          networks: struct describing the networks needed by the learner; this can
            be specific to the learner in question.
          dataset: iterator over samples from replay.
          replay_client: client which allows communication with replay, e.g. in
            order to update priorities.
          counter: a Counter which allows for recording of counts (learner steps,
            actor steps, etc.) distributed throughout the agent.
        """
        pass
